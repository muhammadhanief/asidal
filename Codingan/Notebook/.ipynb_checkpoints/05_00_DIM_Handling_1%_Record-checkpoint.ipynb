{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5816fa69",
   "metadata": {},
   "source": [
    "# Inilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02162682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#For 3.3.1\n",
    "#Register Sedona Functions to Spark\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "\n",
    "#For 3.3.2\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "import h3.api.numpy_int as h3int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a608c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, count, countDistinct, when, expr, first, desc\n",
    "import calendar\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520986fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e51785cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "base_path = \"s3a://ungp-ais-data-historical-backup/user_temp/\"\n",
    "path_unique = base_path + \"222011349/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f885d",
   "metadata": {},
   "source": [
    "# Read 1% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cb64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data_sampel = spark.read.parquet(path_unique + \"data-ais-1persen-dunia-2022.parquet\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373edac5",
   "metadata": {},
   "source": [
    "# DIM Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed80d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil data dua bulan aja\n",
    "\n",
    "data_2endmonth = data_sampel.withColumn(\"months\", F.date_format(\"dt_pos_utc\", \"MMMM\")) \\\n",
    "    .filter((F.col(\"months\") == \"November\") | (F.col(\"months\") == \"December\")).select(\"mmsi\",\"imo\",\"vessel_type_code\",\"flag_code\",\"dt_pos_utc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106947e7",
   "metadata": {},
   "source": [
    "## MMSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d8d4e",
   "metadata": {},
   "source": [
    "### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61db4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------------+\n",
      "|mmsi|imo    |dt_pos_utc         |\n",
      "+----+-------+-------------------+\n",
      "|0   |null   |2022-11-15 16:51:57|\n",
      "|0   |null   |2022-11-15 01:30:25|\n",
      "|0   |8138243|2022-11-15 09:29:27|\n",
      "|0   |null   |2022-11-15 10:53:07|\n",
      "|0   |null   |2022-11-19 19:15:50|\n",
      "|0   |null   |2022-11-14 21:44:33|\n",
      "|0   |null   |2022-11-19 18:32:42|\n",
      "|0   |null   |2022-11-16 10:56:28|\n",
      "|0   |null   |2022-11-19 13:10:36|\n",
      "|0   |8138243|2022-11-19 23:36:03|\n",
      "|0   |6924404|2022-11-09 19:07:59|\n",
      "|0   |8138243|2022-11-11 14:42:41|\n",
      "|0   |null   |2022-11-09 00:56:09|\n",
      "|0   |null   |2022-11-19 13:12:05|\n",
      "|0   |8138243|2022-11-16 10:06:44|\n",
      "|0   |null   |2022-11-14 22:10:05|\n",
      "|0   |null   |2022-11-17 10:23:02|\n",
      "|0   |null   |2022-11-17 02:29:36|\n",
      "|0   |8138243|2022-11-17 20:29:18|\n",
      "|0   |null   |2022-11-11 22:30:07|\n",
      "|0   |null   |2022-11-12 16:40:39|\n",
      "|0   |8138243|2022-11-18 17:15:03|\n",
      "|0   |null   |2022-11-19 12:09:31|\n",
      "|0   |null   |2022-11-19 06:20:32|\n",
      "|0   |null   |2022-11-17 18:10:23|\n",
      "|0   |null   |2022-11-18 01:07:52|\n",
      "|0   |null   |2022-11-11 22:45:59|\n",
      "|0   |null   |2022-11-13 09:40:08|\n",
      "|0   |null   |2022-11-13 14:31:07|\n",
      "|0   |8138243|2022-11-18 19:38:42|\n",
      "|0   |null   |2022-11-16 01:16:33|\n",
      "|0   |null   |2022-11-16 14:53:19|\n",
      "|0   |8728749|2022-11-11 00:25:24|\n",
      "|0   |null   |2022-11-14 00:52:20|\n",
      "|0   |8138243|2022-11-11 12:51:33|\n",
      "|0   |8138243|2022-11-12 23:33:36|\n",
      "|0   |8138243|2022-11-14 21:24:02|\n",
      "|0   |null   |2022-11-16 11:27:48|\n",
      "|0   |null   |2022-11-16 19:00:20|\n",
      "|0   |null   |2022-11-10 10:59:01|\n",
      "|0   |null   |2022-11-12 03:19:32|\n",
      "|0   |8138243|2022-11-12 21:26:35|\n",
      "|0   |null   |2022-11-11 03:03:50|\n",
      "|0   |8138243|2022-11-17 19:20:43|\n",
      "|0   |null   |2022-11-17 07:40:08|\n",
      "|0   |null   |2022-11-17 13:35:37|\n",
      "|0   |null   |2022-11-17 02:35:06|\n",
      "|0   |null   |2022-11-17 01:08:55|\n",
      "|0   |8138243|2022-11-18 01:28:58|\n",
      "|0   |8138243|2022-11-18 21:51:11|\n",
      "|0   |null   |2022-11-18 05:15:56|\n",
      "|0   |8138243|2022-11-18 21:58:41|\n",
      "|0   |8138243|2022-11-18 20:09:49|\n",
      "|0   |8138243|2022-11-18 14:00:22|\n",
      "|0   |null   |2022-11-08 21:50:15|\n",
      "|0   |null   |2022-11-08 23:35:04|\n",
      "|0   |8138243|2022-11-08 16:57:33|\n",
      "|0   |null   |2022-11-10 21:18:29|\n",
      "|0   |null   |2022-11-16 16:04:05|\n",
      "+----+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Tentukan nilai default\n",
    "default_value_1 = 0\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "mmsi_default_value_1 = data_2endmonth.filter(F.col(\"mmsi\") == default_value_1)\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "mmsi_default_value_1.show(mmsi_default_value_1.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38e97ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+\n",
      "|mmsi   |imo      |dt_pos_utc         |\n",
      "+-------+---------+-------------------+\n",
      "|1193046|303174162|2022-11-15 12:00:36|\n",
      "|1193046|303174162|2022-11-14 00:40:57|\n",
      "|1193046|303174162|2022-11-13 19:07:20|\n",
      "|1193046|303174162|2022-11-09 13:37:57|\n",
      "|1193046|303174162|2022-11-09 07:03:41|\n",
      "|1193046|303174162|2022-11-17 20:49:34|\n",
      "|1193046|303174162|2022-11-14 11:36:59|\n",
      "|1193046|303174162|2022-11-12 16:01:18|\n",
      "|1193046|303174162|2022-11-12 06:33:08|\n",
      "|1193046|303174162|2022-11-14 04:41:41|\n",
      "|1193046|303174162|2022-11-10 20:05:57|\n",
      "|1193046|303174162|2022-11-17 15:04:31|\n",
      "|1193046|303174162|2022-11-17 18:46:21|\n",
      "|1193046|303174162|2022-11-17 06:37:30|\n",
      "|1193046|303174162|2022-11-13 19:57:41|\n",
      "|1193046|303174162|2022-11-13 11:56:10|\n",
      "|1193046|303174162|2022-11-11 05:43:38|\n",
      "|1193046|303174162|2022-11-11 05:06:37|\n",
      "|1193046|303174162|2022-11-11 06:46:18|\n",
      "+-------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Tentukan nilai default\n",
    "default_value_2 = 1193046\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "mmsi_default_value_2 = data_2endmonth.filter(F.col(\"mmsi\") == default_value_2)\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "mmsi_default_value_2.show(mmsi_default_value_2.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a66a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Handling MMSI Default\n",
    "\n",
    "def process_default_mmsi(df_data_spark):\n",
    "    # 1. Cek MMSI yang default\n",
    "    default_mmsi_data = df_data_spark.filter((F.col('mmsi') == 0) | (F.col('mmsi') == 1193046))\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in default_mmsi_data.collect():\n",
    "        mmsi = row['mmsi']\n",
    "        imo = row['imo']\n",
    "\n",
    "        # 3. Cek pasangan IMO-nya\n",
    "        joined_data = df_data_spark.filter(F.col('imo') == imo)\n",
    "\n",
    "        # 4. Filter IMO yang valid\n",
    "        valid_imo_data = joined_data.filter(\n",
    "            (F.col('imo') >= 1000000) & (F.col('imo') <= 9999999)\n",
    "        )\n",
    "\n",
    "        # 5. Ambil nilai MMSI yang valid dari IMO\n",
    "        valid_mmsi_data = valid_imo_data.groupBy('imo', 'mmsi').agg(\n",
    "            F.countDistinct('mmsi').alias('count')\n",
    "        )\n",
    "\n",
    "        max_count_data = valid_mmsi_data.groupBy('imo').agg(\n",
    "            F.max('count').alias('max_count'),\n",
    "            F.first('mmsi', ignorenulls=True).alias('mmsi_replacement')\n",
    "        )\n",
    "\n",
    "        # 6. Gantikan nilai MMSI yang default dengan nilai yang valid\n",
    "        mmsi_replacement_row = max_count_data.where(max_count_data['imo'] == imo).select('mmsi_replacement').first()\n",
    "\n",
    "        if mmsi_replacement_row:\n",
    "            mmsi_replacement = mmsi_replacement_row['mmsi_replacement']\n",
    "\n",
    "            df_data_spark = df_data_spark.withColumn(\n",
    "                \"mmsi\",\n",
    "                F.when(\n",
    "                    (F.col(\"mmsi\") == mmsi) & (F.col(\"imo\") == imo),\n",
    "                    mmsi_replacement\n",
    "                ).otherwise(F.col(\"mmsi\"))\n",
    "            )\n",
    "\n",
    "    # 7. Drop kolom tambahan\n",
    "    df_data_spark = df_data_spark.drop(\"mmsi_replacement\", \"imo\")\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8052e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksekusi Fungsi\n",
    "\n",
    "data_mmsid_hand = process_default_mmsi(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e63fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "#data_mmsid_hand.write.option(\"header\", True).mode(\"overwrite\").parquet(path_unique + \"data-ais-mmsid-handling-coba.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ce390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "\n",
    "# data_mmsid_hand = spark.read.parquet(path_unique + \"data-ais-mmsid-handling-coba.parquet\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4593fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek Lagi\n",
    "\n",
    "# Tentukan nilai default\n",
    "default_value_1 = 0\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "mmsi_default_value_1 = data_mmsid_hand.filter(F.col(\"mmsi\") == default_value_1)\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "mmsi_default_value_1.show(mmsi_default_value_1.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0553ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek Lagi\n",
    "\n",
    "# Tentukan nilai default\n",
    "default_value_2 = 1193046\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "mmsi_default_value_2 = data_mmsid_hand.filter(F.col(\"mmsi\") == default_value_2).select(\"mmsi\",\"imo\")\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "mmsi_default_value_2.show(mmsi_default_value_2.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66979a8f",
   "metadata": {},
   "source": [
    "### Invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Filter nilai MMSI yang invalid\n",
    "filtered_data = data_2endmonth.filter(\n",
    "    ~(\n",
    "        ((col('mmsi') >= 100000000) & (col('mmsi') <= 999999999)) |\n",
    "        (col('mmsi') == 0) |\n",
    "        (col('mmsi') == 1193046)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"mmsi\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Handling MMSI Invalid\n",
    "\n",
    "def process_invalid_mmsi(df_data_spark):\n",
    "    # 1. Cek MMSI yang invalid\n",
    "    invalid_mmsi_data = df_data_spark.filter(\n",
    "        ~(\n",
    "            ((col('mmsi') >= 100000000) & (col('mmsi') <= 999999999)) |\n",
    "            (col('mmsi') == 0) |\n",
    "            (col('mmsi') == 1193046)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in invalid_mmsi_data:\n",
    "        mmsi = row['mmsi']\n",
    "        imo = row['imo']\n",
    "\n",
    "        # 3. Cek pasangan IMO-nya\n",
    "        joined_data = df_data_spark.filter(col('imo') == imo)\n",
    "\n",
    "        # 4. Filter IMO yang valid\n",
    "        valid_imo_data = joined_data.filter(\n",
    "            (col('imo') >= 1000000) & (col('imo') <= 9999999)\n",
    "        )\n",
    "\n",
    "        # 5. Ambil nilai MMSI yang valid dari IMO\n",
    "        valid_mmsi_data = valid_imo_data.groupBy('imo', 'mmsi').agg(\n",
    "            countDistinct('mmsi').alias('count')\n",
    "        )\n",
    "\n",
    "        max_count_data = valid_mmsi_data.groupBy('imo').agg(\n",
    "            first('mmsi', 'count').alias('mmsi_replacement')\n",
    "        )\n",
    "\n",
    "        # 6. Gantikan nilai MMSI yang invalid dengan nilai yang valid\n",
    "        df_data_spark = df_data_spark.withColumn(\n",
    "            \"mmsi\",\n",
    "            when(\n",
    "                (col(\"mmsi\") == mmsi) & (col(\"imo\") == imo),\n",
    "                max_count_data.select(\"mmsi_replacement\").first()[0]\n",
    "            ).otherwise(col(\"mmsi\"))\n",
    "        )\n",
    "\n",
    "    # 7. Drop kolom tambahan\n",
    "    df_data_spark = df_data_spark.drop(\"mmsi_replacement\", \"imo\")\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c45fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksekusi fungsi\n",
    "data_mmsii_hand = process_invalid_mmsi(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek lagi\n",
    "\n",
    "# Filter nilai MMSI yang invalid\n",
    "filtered_data = data_mmsii_hand.filter(\n",
    "    ~(\n",
    "        ((col('mmsi') >= 100000000) & (col('mmsi') <= 999999999)) |\n",
    "        (col('mmsi') == 0) |\n",
    "        (col('mmsi') == 1193046)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"mmsi\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa23041",
   "metadata": {},
   "source": [
    "## IMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8253a",
   "metadata": {},
   "source": [
    "### Default & Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d442c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+---------+-------------------+\n",
      "|     mmsi| imo|vessel_type_code|flag_code|         dt_pos_utc|\n",
      "+---------+----+----------------+---------+-------------------+\n",
      "|257078960|null|              70|      257|2022-12-31 21:24:16|\n",
      "|257619800|null|              70|      257|2022-12-31 21:41:15|\n",
      "|258025670|null|              70|      258|2022-12-31 18:41:04|\n",
      "|257059820|null|              30|      257|2022-12-31 21:24:31|\n",
      "|257010740|null|              30|      257|2022-12-31 19:55:58|\n",
      "|257116240|null|              30|      257|2022-12-31 20:13:01|\n",
      "|257084640|null|              30|      257|2022-12-31 18:58:59|\n",
      "|257112140|null|              30|      257|2022-12-31 18:29:50|\n",
      "|257126040|null|              30|      257|2022-12-31 19:31:52|\n",
      "|257220140|null|              30|      257|2022-12-31 20:37:51|\n",
      "|257405320|null|              30|      257|2022-12-31 19:12:01|\n",
      "|257458920|null|              30|      257|2022-12-31 21:00:49|\n",
      "|257974630|null|              37|      257|2022-12-31 21:15:20|\n",
      "|257042250|null|              30|      257|2022-12-31 20:10:39|\n",
      "|257129140|null|              30|      257|2022-12-31 21:32:09|\n",
      "|259011540|null|              30|      259|2022-12-31 18:43:46|\n",
      "|257101120|null|              30|      257|2022-12-31 21:28:05|\n",
      "|257143920|null|              30|      257|2022-12-31 19:51:01|\n",
      "|257060930|null|              30|      257|2022-12-31 19:47:33|\n",
      "|257095540|null|              30|      257|2022-12-31 19:30:55|\n",
      "+---------+----+----------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "imo_default_miss_value = data_2endmonth.filter((F.col('imo') == 0) | (F.col('imo').isNull()))\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "imo_default_miss_value.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d78d634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5860717"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imo_default_miss_value.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0baeeb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi handling IMO Default dan Missing\n",
    "\n",
    "def process_default_miss_imo(df_data_spark):\n",
    "    # 1. Cek IMO yang default atau missing\n",
    "    default_imo_data = df_data_spark.filter((F.col('imo') == 0) | (F.col('imo').isNull()))\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in default_imo_data.collect():\n",
    "        mmsi = row['mmsi']\n",
    "        imo = row['imo']\n",
    "\n",
    "        # 3. Cek pasangan MMSI-nya\n",
    "        joined_data = df_data_spark.filter(F.col('mmsi') == mmsi)\n",
    "\n",
    "        # 4. Filter MMSI yang valid\n",
    "        valid_mmsi_data = joined_data.filter(\n",
    "            (F.col('mmsi') >= 100000000) & (F.col('mmsi') <= 999999999)\n",
    "        )\n",
    "\n",
    "        # 5. Ambil nilai IMO yang valid dari MMSI\n",
    "        valid_imo_data = valid_mmsi_data.groupBy('imo', 'mmsi').agg(\n",
    "            F.countDistinct('imo').alias('count')\n",
    "        )\n",
    "\n",
    "        max_count_data = valid_imo_data.groupBy('mmsi').agg(\n",
    "            F.max('count').alias('max_count'),\n",
    "            F.first('imo', ignorenulls=True).alias('imo_replacement')\n",
    "        )\n",
    "\n",
    "        # 6. Gantikan nilai IMO yang default atau missing dengan nilai yang valid\n",
    "        imo_replacement_row = max_count_data.where(max_count_data['mmsi'] == mmsi).select('imo_replacement').first()\n",
    "\n",
    "        if imo_replacement_row:\n",
    "            imo_replacement = imo_replacement_row['imo_replacement']\n",
    "\n",
    "            df_data_spark = df_data_spark.withColumn(\n",
    "                \"imo\",\n",
    "                F.when(\n",
    "                    (F.col(\"imo\") == imo) & (F.col(\"mmsi\") == mmsi),\n",
    "                    imo_replacement\n",
    "                ).otherwise(F.col(\"imo\"))\n",
    "            )\n",
    "\n",
    "    # 7. Drop kolom tambahan\n",
    "    df_data_spark = df_data_spark.drop(\"imo_replacement\", \"mmsi\")\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64628dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=3>\n",
      "Closing down clientserver connection\n",
      "Closing down clientserver connection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=3>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR: KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Eksekusi Fungsi\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data_imodm_hand \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_default_miss_imo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_2endmonth\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mprocess_default_miss_imo\u001b[0;34m(df_data_spark)\u001b[0m\n\u001b[1;32m     25\u001b[0m max_count_data \u001b[38;5;241m=\u001b[39m valid_imo_data\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmsi\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m     26\u001b[0m     F\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_count\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     27\u001b[0m     F\u001b[38;5;241m.\u001b[39mfirst(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimo\u001b[39m\u001b[38;5;124m'\u001b[39m, ignorenulls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimo_replacement\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 6. Gantikan nilai IMO yang default atau missing dengan nilai yang valid\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m imo_replacement_row \u001b[38;5;241m=\u001b[39m \u001b[43mmax_count_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_count_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmmsi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmmsi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimo_replacement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imo_replacement_row:\n\u001b[1;32m     34\u001b[0m     imo_replacement \u001b[38;5;241m=\u001b[39m imo_replacement_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimo_replacement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:1938\u001b[0m, in \u001b[0;36mDataFrame.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Row]:\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the first row as a :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1930\u001b[0m \n\u001b[1;32m   1931\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;124;03m    Row(age=2, name='Alice')\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:1924\u001b[0m, in \u001b[0;36mDataFrame.head\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the first ``n`` rows.\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice')]\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1924\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m rs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(n)\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:1926\u001b[0m, in \u001b[0;36mDataFrame.head\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m rs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:868\u001b[0m, in \u001b[0;36mDataFrame.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtake\u001b[39m(\u001b[38;5;28mself\u001b[39m, num: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Row]:\n\u001b[1;32m    859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the first ``num`` rows as a :class:`list` of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;124;03m    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Eksekusi Fungsi\n",
    "\n",
    "data_imodm_hand = process_default_miss_imo(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek lagi\n",
    "\n",
    "# Hitung jumlah 'mmsi' dengan nilai default per bulan\n",
    "imo_default_miss_value = data_imodm_hand.filter((F.col('imo') == 0) | (F.col('imo').isNull()))\n",
    "\n",
    "# Tampilkan DataFrame Spark hasil akhir\n",
    "imo_default_miss_value.show(imo_default_miss_value.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992faed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imo_default_miss_value.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc9f28",
   "metadata": {},
   "source": [
    "### Invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f854e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Filter nilai IMO yang invalid\n",
    "filtered_data = data_2endmonth.filter(\n",
    "    ~(\n",
    "        ((col('imo') >= 1000000) & (col('imo') <= 9999999)) |\n",
    "        (col('imo') == 0) |\n",
    "        (col('imo').isNull())\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"imo\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03155b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi handling IMO Invalid\n",
    "\n",
    "def process_invalid_imo(df_data_spark):\n",
    "    # 1. Cek IMO yang invalid\n",
    "    invalid_imo_data = df_data_spark.filter(\n",
    "        ~(\n",
    "            ((col('imo') >= 1000000) & (col('imo') <= 9999999)) |\n",
    "            (col('imo') == 0) |\n",
    "            (col('imo').isNull())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in invalid_imo_data:\n",
    "        mmsi = row['mmsi']\n",
    "        imo = row['imo']\n",
    "\n",
    "        # 3. Cek pasangan MMSI-nya\n",
    "        joined_data = df_data_spark.filter(col('mmsi') == mmsi)\n",
    "\n",
    "        # 4. Filter MMSI yang valid\n",
    "        valid_mmsi_data = joined_data.filter(\n",
    "            (col('mmsi') >= 100000000) & (col('mmsi') <= 999999999)\n",
    "        )\n",
    "\n",
    "        # 5. Ambil nilai IMO yang valid dari MMSI\n",
    "        valid_imo_data = valid_mmsi_data.groupBy('imo', 'mmsi').agg(\n",
    "            countDistinct('imo').alias('count')\n",
    "        )\n",
    "\n",
    "        max_count_data = valid_imo_data.groupBy('mmsi').agg(\n",
    "            first('imo', 'count').alias('imo_replacement')\n",
    "        )\n",
    "\n",
    "        # 6. Gantikan nilai IMO yang invalid dengan nilai yang valid\n",
    "        df_data_spark = df_data_spark.withColumn(\n",
    "            \"imo\",\n",
    "            when(\n",
    "                (col(\"imo\") == imo) & (col(\"mmsi\") == mmsi),\n",
    "                max_count_data.select(\"imo_replacement\").first()[0]\n",
    "            ).otherwise(col(\"imo\"))\n",
    "        )\n",
    "\n",
    "    # 7. Drop kolom tambahan\n",
    "    df_data_spark = df_data_spark.drop(\"imo_replacement\", \"mmsi\")\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksekusi Fungsi\n",
    "\n",
    "data_imoi_hand = process_invalid_imo(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek lagi\n",
    "\n",
    "# Filter nilai IMO yang invalid\n",
    "filtered_data = data_imoi_hand.filter(\n",
    "    ~(\n",
    "        ((col('imo') >= 1000000) & (col('imo') <= 9999999)) |\n",
    "        (col('imo') == 0) |\n",
    "        (col('imo').isNull())\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"imo\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0de8a",
   "metadata": {},
   "source": [
    "## Tipe Kapal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Filter nilai vess_type yang default atau invalid\n",
    "filtered_data = data_2endmonth.filter(\n",
    "    ((col('vessel_type_code') < 1) | (col('vessel_type_code') > 255)) | (col('vessel_type_code') == 0)\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"vessel_type_code\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi handling Vess_Type Default dan Invalid\n",
    "\n",
    "def process_default_invalid_vessel_type(df_data_spark):\n",
    "    # 1. Cek Vess_type yang default atau missing\n",
    "    default_vessel_type_data = df_data_spark.filter(((col('vessel_type_code') < 1) | (col('vessel_type_code') > 255)) | (col('vessel_type_code') == 0))\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in default_vessel_type_data.collect():\n",
    "        mmsi = row['mmsi']\n",
    "        vessel_type_code = row['vessel_type_code']\n",
    "\n",
    "        # 3. Cek pasangan MMSI-nya\n",
    "        joined_data = df_data_spark.filter(F.col('mmsi') == mmsi)\n",
    "\n",
    "        # 4. Filter MMSI yang valid\n",
    "        valid_mmsi_data = joined_data.filter(\n",
    "            (F.col('mmsi') >= 100000000) & (F.col('mmsi') <= 999999999)\n",
    "        )\n",
    "\n",
    "        # 5. Ambil nilai Vess_type yang valid dari MMSI\n",
    "        valid_vessel_type_code_data = valid_mmsi_data.groupBy('vessel_type_code', 'mmsi').agg(\n",
    "            F.countDistinct('vessel_type_code').alias('count')\n",
    "        )\n",
    "\n",
    "        max_count_data = valid_vessel_type_code_data.groupBy('mmsi').agg(\n",
    "            F.max('count').alias('max_count'),\n",
    "            F.first('vessel_type_code', ignorenulls=True).alias('vessel_type_code_replacement')\n",
    "        )\n",
    "\n",
    "        # 6. Gantikan nilai IMO yang default atau missing dengan nilai yang valid\n",
    "        vessel_type_code_replacement_row = max_count_data.where(max_count_data['mmsi'] == mmsi).select('vessel_type_code_replacement').first()\n",
    "\n",
    "        if vessel_type_code_replacement_row:\n",
    "            vessel_type_code_replacement = vessel_type_code_replacement_row['vessel_type_code_replacement']\n",
    "\n",
    "            df_data_spark = df_data_spark.withColumn(\n",
    "                \"vessel_type_code\",\n",
    "                F.when(\n",
    "                    (F.col(\"vessel_type_code\") == imo) & (F.col(\"mmsi\") == mmsi),\n",
    "                    vessel_type_code_replacement\n",
    "                ).otherwise(F.col(\"vessel_type_code\"))\n",
    "            )\n",
    "\n",
    "    # 7. Drop kolom tambahan\n",
    "    df_data_spark = df_data_spark.drop(\"vessel_type_code_replacement\", \"mmsi\")\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e594596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksekusi Fungsi\n",
    "\n",
    "data_vesstypedi_hand = process_default_invalid_vessel_type(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek lagi\n",
    "\n",
    "# Filter nilai vess_type yang default atau invalid\n",
    "filtered_data = data_vesstypedi_hand.filter(\n",
    "    ((col('vessel_type_code') < 1) | (col('vessel_type_code') > 255)) | (col('vessel_type_code') == 0)\n",
    ")\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"vessel_type_code\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16c82b",
   "metadata": {},
   "source": [
    "## Negara Kapal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6edfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Filter nilai flag_code yang null\n",
    "filtered_data = data_2endmonth.filter(col('flag_code').isNull())\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"mmsi\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi handling Missing Flag_Code\n",
    "\n",
    "def process_missing_flag_code(df_data_spark):\n",
    "    # 1. Cek Flag_Code yang null\n",
    "    missing_flag_code_data = df_data_spark.filter(F.col('flag_code').isNull())\n",
    "\n",
    "    # 2. Loop melalui setiap record dan langsung ubah dalam DataFrame Spark\n",
    "    for row in missing_flag_code_data.collect():\n",
    "        mmsi = row['mmsi']\n",
    "        flag_code = row['flag_code']\n",
    "\n",
    "        # 3. Cek pasangan MMSI-nya\n",
    "        joined_data = df_data_spark.filter(F.col('mmsi') == mmsi)\n",
    "\n",
    "        # 4. Filter MMSI yang valid\n",
    "        valid_mmsi_data = joined_data.filter(\n",
    "            (F.col('mmsi') >= 100000000) & (F.col('mmsi') <= 999999999)\n",
    "        )\n",
    "\n",
    "        # 5. Gantikan nilai flag_code yang null dengan 3 digit pertama dari mmsi jika mmsi valid\n",
    "        df_data_spark = df_data_spark.withColumn(\n",
    "            \"flag_code\",\n",
    "            F.when(\n",
    "                (F.col(\"flag_code\").isNull()) & (F.col(\"mmsi\") >= 100000000) & (F.col(\"mmsi\") <= 999999999),\n",
    "                F.substring(F.col(\"mmsi\").cast(\"string\"), 1, 3)\n",
    "            ).otherwise(F.col(\"flag_code\"))\n",
    "        )\n",
    "\n",
    "    return df_data_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksekusi Fungsi\n",
    "\n",
    "data_flagcodem_hand = process_missing_flag_code(data_2endmonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek dulu\n",
    "\n",
    "# Filter nilai flag_code yang null\n",
    "filtered_data = data_flagcodem_hand.filter(col('flag_code').isNull())\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "filtered_data = filtered_data.orderBy(\"mmsi\")\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b21f13",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aadac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "sampledd_data.write.option(\"header\", True).mode(\"overwrite\").parquet(path_unique + \"data-ais-1persen-dimhandling-dunia-2022.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template ais-tt-dev",
   "language": "python3",
   "name": "ais-tt-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
